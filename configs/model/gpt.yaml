_target_: src.models.gpt_module.GPTLitModule
learning_rate: 1e-3
block_size: ${datamodule.block_size} # Use from datamodule as both needs to be same

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 0.001
  weight_decay: 0.0

net:
  _target_: src.models.gpt_module.GPT
  vocab_size: 100277
  block_size: ${datamodule.block_size} # Use from datamodule as both needs to be same
  n_embed: 64
  n_heads: 4
  drop_p: 0.
  n_decoder_blocks: 4

